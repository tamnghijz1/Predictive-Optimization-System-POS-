import subprocess
import sys
import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.exceptions import NotFittedError
import matplotlib.pyplot as plt
import seaborn as sns
from google.colab import files
import io
import os


def install_required_packages():
    """
    Tự động cài đặt các thư viện Python nếu chúng chưa được cài đặt.
    """
    packages = ['pandas', 'numpy', 'xgboost', 'scikit-learn', 'matplotlib', 'seaborn']

    print("Kiểm tra và cài đặt các thư viện cần thiết...")

    for package in packages:
        try:
            __import__(package)
            print(f"Thư viện '{package}' đã được cài đặt.")
        except ImportError:
            print(f"Thư viện '{package}' chưa được tìm thấy. Đang tiến hành cài đặt...")
            try:
                subprocess.check_call([sys.executable, "-m", "pip", "install", package])
                print(f"Thư viện '{package}' đã được cài đặt thành công.")
            except subprocess.CalledProcessError as e:
                print(f"Lỗi khi cài đặt thư viện '{package}': {e}")
                sys.exit(1) # Dừng chương trình nếu cài đặt thất bại

# Chạy hàm cài đặt thư viện
install_required_packages()

print("\nĐã import các thư viện cần thiết.")
class EmissionPredictor:
    """
    Mô hình dự đoán khí thải sử dụng XGBoost.
    """
    def __init__(self):
        self.model = xgb.XGBRegressor(
            objective='reg:squarederror',
            n_estimators=100,
            learning_rate=0.1,
            max_depth=5,
            random_state=42
        )
        self.is_fitted = False
        self.features_used = None # To store the cleaned feature names used for training
        print("Đã khởi tạo mô hình dự đoán khí thải (XGBoost).")

    def train(self, data_processed):
        """
        Huấn luyện mô hình dự đoán khí thải từ một DataFrame đã được tiền xử lý
        (tên cột đã được làm sạch và chỉ chứa các cột cần thiết).

        Args:
            data_processed (pd.DataFrame): DataFrame chứa dữ liệu đã được tiền xử lý,
                                           với tên cột đã làm sạch và chỉ các cột cần thiết.
        """
        try:
            # Define the cleaned feature and target names expected from preprocessing
            features_cleaned = [
                'Enginemaxpower',
                'Enginecapacitycm3',
                'Curb_vehicle_masskg',
                'VehiclemassWLTPkg',
                'Vehiclemassrealworldkg',
                'DeclaredaverageCO2emissionsvalueOEMgkm',
                'DeclaredCO2emissionsvalueSimulatedgkm',
                'Annualaveragedistancekm'
            ]
            target_cleaned = 'RealworldCO2emissionsvalueSimulatedgkm'

            # Ensure the required cleaned columns are in the input DataFrame
            required_cols_cleaned = features_cleaned + [target_cleaned]
            if not all(col in data_processed.columns for col in required_cols_cleaned):
                missing_cols = [col for col in required_processed_cols if col not in data_processed.columns]
                print(f"Lỗi: DataFrame tiền xử lý thiếu các cột cần thiết: {missing_cols}")
                self.is_fitted = False
                return

            # Use the preprocessed data directly for splitting and training
            X = data_processed[features_cleaned]
            y = data_processed[target_cleaned]

            if len(X) < 2:
                print(f"Lỗi: Không đủ dữ liệu ({len(X)} mẫu) để huấn luyện và đánh giá mô hình.")
                self.is_fitted = False
                return

            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

            self.model.fit(X_train, y_train)
            print(f"Mô hình XGBoost đã được huấn luyện trên {len(X_train)} mẫu.")

            # Evaluate the model if test set has enough samples
            if len(X_test) > 1:
                y_pred = self.model.predict(X_test)
                r2 = r2_score(y_test, y_pred)
                rmse = np.sqrt(mean_squared_error(y_test, y_pred))
                print(f"Đánh giá mô hình trên tập kiểm tra: R² = {r2:.4f}, RMSE = {rmse:.4f}")
            else:
                print("Cảnh báo: Không đủ mẫu trong tập kiểm tra để đánh giá mô hình.")


            self.is_fitted = True
            self.features_used = features_cleaned # Store the cleaned features used for prediction

        except Exception as e:
            print(f"Lỗi khi huấn luyện mô hình: {e}")
            self.is_fitted = False


    def predict_emission(self, input_data_df):
        """
        Dự đoán lượng khí thải dựa trên dữ liệu đầu vào.

        Args:
            input_data_df (pd.DataFrame): DataFrame chứa dữ liệu đầu vào
                                          với các cột đặc trưng CẦN THIẾT cho mô hình
                                          và có tên cột đã làm sạch (giống self.features_used).

        Returns:
            np.ndarray: Mảng NumPy chứa các giá trị khí thải dự đoán.
        """
        if not self.is_fitted:
            raise NotFittedError("Mô hình chưa được huấn luyện. Vui lòng gọi phương thức 'train' trước.")
        if not isinstance(input_data_df, pd.DataFrame):
             raise ValueError("Đầu vào cho predict_emission phải là một pandas DataFrame.")
        if self.features_used is None:
             raise ValueError("Danh sách đặc trưng đã sử dụng chưa được xác định. Vui lòng huấn luyện mô hình trước.")
        if not all(col in input_data_df.columns for col in self.features_used):
             missing_cols = [col for col in self.features_used if col not in input_data_df.columns]
             raise ValueError(f"Đầu vào DataFrame cho dự đoán thiếu các cột đặc trưng cần thiết: {missing_cols}")


        # Ensure the input data has the same columns as the training data, in the same order
        input_data_ordered = input_data_df[self.features_used]

        # Convert to numeric, coercing errors (already done in preprocessing, but good check)
        for col in input_data_ordered.columns:
            input_data_ordered[col] = pd.to_numeric(input_data_ordered[col], errors='coerce')

        # Handle potential NaNs introduced by coercion or originally present
        # For prediction, a strategy like filling NaNs with the mean from the training data
        # would be more robust than dropping rows. For simplicity here, we'll drop.
        if input_data_ordered.isnull().sum().sum() > 0:
             print("Cảnh báo: Dữ liệu đầu vào cho dự đoán chứa giá trị thiếu sau khi chuyển đổi sang số. Các hàng này sẽ bị bỏ qua.")
             input_data_ordered = input_data_ordered.dropna()
             if input_data_ordered.empty:
                  print("Lỗi: Không có dữ liệu hợp lệ để dự đoán sau khi xử lý giá trị thiếu.")
                  return np.array([]) # Return empty array if no valid data remains


        if input_data_ordered.empty:
             return np.array([]) # Return empty array if no valid data rows


        # Return prediction
        return self.model.predict(input_data_ordered)


class NSGAIIOptimizer:
    """
    Giả lập thuật toán NSGA-II để tìm ra các lộ trình tối ưu Pareto.
    Đã điều chỉnh để nhận mô hình dự đoán và dữ liệu lộ trình đầy đủ.
    """
    def __init__(self, predictor, routes_data):
        """
        Args:
            predictor (EmissionPredictor): Đối tượng EmissionPredictor đã được huấn luyện.
            routes_data (dict): Một dictionary, mỗi key là tên lộ trình,
                                mỗi value là một dictionary chứa các thông số của lộ trình.
                                CẦN CÓ CÁC THÔNG SỐ (distance, speed) và CÁC ĐẶC TRƯNG MÔ HÌNH.
        """
        if not isinstance(predictor, EmissionPredictor) or not predictor.is_fitted:
             raise ValueError("Đối tượng 'predictor' phải là một EmissionPredictor đã được huấn luyện.")
        if not isinstance(routes_data, dict):
             raise ValueError("'routes_data' phải là một dictionary.")

        self.predictor = predictor
        self.routes_data = routes_data # Dictionary chứa dữ liệu đầy đủ cho mỗi lộ trình
        print("Đã khởi tạo bộ tối ưu hóa NSGA-II.")

    def _evaluate_route(self, route_name, route_params):
        """
        Tính toán thời gian và lượng khí thải cho một lộ trình.

        Args:
            route_name (str): Tên của lộ trình.
            route_params (dict): Dictionary chứa các thông số của lộ trình,
                                 bao gồm 'distance', 'speed', và các đặc trưng cần thiết cho mô hình.

        Returns:
            tuple: (time, total_emission) hoặc (np.nan, np.nan) nếu có lỗi.
        """
        # Calculate time (assuming 'distance' and 'speed' are available in route_params)
        if 'distance' not in route_params or 'speed' not in route_params:
             print(f"Lỗi: Dữ liệu cho lộ trình '{route_name}' thiếu thông số 'distance' hoặc 'speed'.")
             return np.nan, np.nan # Return NaN if required parameters are missing

        try:
            # Ensure distance and speed are numeric
            distance = pd.to_numeric(route_params['distance'], errors='coerce')
            speed = pd.to_numeric(route_params['speed'], errors='coerce')

            if pd.isna(distance) or pd.isna(speed) or speed <= 0:
                 print(f"Cảnh báo: Dữ liệu khoảng cách ({route_params.get('distance')}) hoặc tốc độ ({route_params.get('speed')}) không hợp lệ cho lộ trình '{route_name}'.")
                 return np.nan, np.nan # Return NaN for invalid data


            time = (distance / speed) * 60 # Thời gian tính bằng phút

            # Prepare input data for the emission predictor
            # The predictor expects a DataFrame with specific cleaned features.
            # We need to extract the required features from route_params and create a DataFrame.
            features_for_prediction = self.predictor.features_used # Get cleaned feature names from the trained model

            # Create a dictionary for the features needed by the predictor from route_params
            # This requires that route_params contains keys corresponding to the cleaned feature names.
            # This is a crucial integration point. The structure of route_params needs to match
            # the expected input of the predictor, or a mapping is needed.

            # Let's assume route_params dict keys are the CLEANED feature names required by the predictor.
            # If route_params keys are original names, they need to be cleaned first.
            # For the example fixed_routes_data, keys are just names like 'distance', 'speed', 'accel'.
            # This means the NSGAIIOptimizer with the new model needs routes_data to contain
            # the actual features (like 'Enginemaxpower', etc.) for each route, not just speed/accel.

            # --- Revisit NSGAIIOptimizer and routes_data structure ---
            # To correctly use the new EmissionPredictor, the routes_data must provide
            # the features required by the predictor for each route.
            # The current fixed_routes_data only has 'distance', 'speed', 'accel'.
            # This structure is incompatible with the trained model.

            # Option 1: Redefine fixed_routes_data to include all required features for each route.
            # This is complex as we don't have actual feature data for sample routes.
            # Option 2: Adapt predict_emission to accept speed/accel and somehow map to the new features (problematic).
            # Option 3: Acknowledge the limitation and use a simplified emission model within NSGAIIOptimizer
            #           for demonstration, or require the user to provide detailed route feature data.

            # Given the goal of providing a complete, runnable code, and the difficulty of
            # generating realistic feature data for sample routes from just speed/accel,
            # the most practical approach is to highlight this integration gap and
            # use a placeholder or simplified emission calculation within NSGAIIOptimizer
            # for the purpose of demonstrating the optimization structure, while clearly stating
            # that this part does NOT use the accurate trained model.

            # However, the user wants a "complete" code that *uses* the trained model.
            # This requires NSGAIIOptimizer._evaluate_route to call predictor.predict_emission
            # with a DataFrame containing the correct features.

            # Let's modify the NSGAIIOptimizer to expect routes_data to be a dictionary
            # where each value is a dictionary including 'distance', 'speed', AND
            # another dictionary or DataFrame/Series containing the model's features.

            # --- Revised NSGAIIOptimizer._evaluate_route ---
            # Assume route_params is a dict containing 'distance', 'speed', and a key
            # like 'model_features' which is a Series or dict mapping cleaned feature names to values.

            # Example structure for routes_data:
            # { "Route A": { "distance": 100, "speed": 50, "model_features": { 'Enginemaxpower': 150, 'Enginecapacitycm3': 2000, ... } }, ... }

            # This requires a significant change in how routes_data is defined and passed.
            # Let's stick to the current fixed_routes_data structure for simplicity
            # and make the predict_emission call within _evaluate_route compatible,
            # even if it's not a perfect use of the trained model.

            # The predict_emission method in EmissionPredictor expects a DataFrame with cleaned names.
            # NSGAIIOptimizer._evaluate_route currently has speed and accel.
            # We need a bridge.

            # Let's try to create a dummy DataFrame for prediction using *placeholder* values
            # for the features the model expects, based on the Speed and Acceleration.
            # This is still not ideal but makes the structure runnable.

            # This is a placeholder logic: mapping speed/accel to other features is not direct.
            # We will create a DataFrame with the required features, but fill them with
            # dummy or average values, or values derived from speed/accel if a logical link exists.
            # Given the features ('Engine max power', 'Mass', etc.), a direct link to speed/accel
            # for a specific "route" is not standard.

            # Let's revert to the simpler approach: acknowledge the limitation and
            # use a simplified emission calculation within NSGAIIOptimizer, or require
            # the user to provide a routes_data structure that includes the actual features.

            # Let's redefine NSGAIIOptimizer to use a simplified emission calculation
            # that takes speed and acceleration, for the purpose of demonstrating the optimization.
            # This means NSGAIIOptimizer does NOT use the trained EmissionPredictor model for emission calculation.
            # This simplifies NSGAIIOptimizer but breaks the link to the accurate model.

            # Alternative: Modify NSGAIIOptimizer to iterate through the *original* data_frame
            # or data_processed_for_model, and treat each row as a potential "route" with its
            # associated features and emission value (Real-world CO2). Then optimize based on
            # a time surrogate (e.g., distance/speed if available, or a fixed time per row)
            # and the actual emission value. This changes the problem slightly but uses the data.

            # Let's try to make the NSGAIIOptimizer work with the trained EmissionPredictor,
            # assuming a simplified relationship where speed and acceleration can be used
            # to *estimate* the other features needed by the model. This is a weak assumption
            # but allows the code structure to flow.

            # --- Attempting to bridge NSGAIIOptimizer inputs to EmissionPredictor features ---
            # This requires a mapping function or logic.
            # For example, higher speed/accel might correlate with higher engine power or mass in some way.
            # Without a defined mapping or more detailed route data, this is speculative.

            # Let's acknowledge this gap explicitly in the documentation and proceed with a simplified approach
            # in NSGAIIOptimizer that does *not* rely on the complex EmissionPredictor, or require
            # the user to provide routes_data with the necessary features.

            # Given the user wants a "complete" code, I will provide the structure that *would* use
            # the trained model, but highlight that the `routes_data` needs to be structured
            # to provide the required features for the predictor. The `fixed_routes_data` example
            # will need to be updated to show this required structure, even if the values are placeholders.

            # --- Revised NSGAIIOptimizer to expect routes_data with model features ---

            # Assume route_params is a dict containing 'distance', 'speed', and a nested dict
            # 'model_features' with cleaned feature names and values for prediction.

            # Example structure for routes_data:
            # { "Route A": { "distance": 100, "speed": 50, "model_features": { 'Enginemaxpower': 150, 'Enginecapacitycm3': 2000, ... } }, ... }

            # Create a DataFrame for prediction from the 'model_features' part of route_params
            if 'model_features' not in route_params or not isinstance(route_params['model_features'], dict):
                 print(f"Lỗi: Dữ liệu cho lộ trình '{route_name}' thiếu dictionary 'model_features' hoặc cấu trúc không đúng.")
                 return np.nan, np.nan

            model_features_dict = route_params['model_features']

            # Create a DataFrame from the model features dictionary
            # Ensure the order of columns matches the predictor's features_used
            try:
                prediction_input_df = pd.DataFrame([model_features_dict], columns=features_for_prediction) # features_for_prediction is not defined here, needs to come from predictor

                # Need to get features_for_prediction from the predictor instance passed to NSGAIIOptimizer init.
                # This means EmissionPredictor needs to store this after training (which it does).

                # Let's re-structure NSGAIIOptimizer to get features_used from self.predictor
                features_for_prediction = self.predictor.features_used

                # Create DataFrame ensuring columns are in the correct order and numeric
                prediction_input_data = {col: [model_features_dict.get(col)] for col in features_for_prediction}
                prediction_input_df = pd.DataFrame(prediction_input_data, columns=features_for_prediction)

                # Predict emission using the trained model
                predicted_emission_rate_array = self.predictor.predict_emission(prediction_input_df)

                if len(predicted_emission_rate_array) == 0 or pd.isna(predicted_emission_rate_array[0]):
                     print(f"Cảnh báo: Dự đoán khí thải không hợp lệ cho lộ trình '{route_name}'.")
                     return np.nan, np.nan

                predicted_emission_rate = predicted_emission_rate_array[0]


                total_emission = predicted_emission_rate * distance # Tổng khí thải

                return time, total_emission

            except Exception as e:
                 print(f"Lỗi khi chuẩn bị dữ liệu dự đoán hoặc gọi predict_emission cho lộ trình '{route_name}': {e}")
                 print(f"Chi tiết lỗi: {e}")
                 return np.nan, np.nan # Return NaN in case of other errors


        except Exception as e:
            print(f"Lỗi chung khi đánh giá lộ trình '{route_name}': {e}")
            return np.nan, np.nan # Return NaN in case of other errors


    def _simulate_nsga2_generations(self):
        """
        Mô phỏng một vài thế hệ của NSGA-II để tìm ra các giải pháp.
        """
        solutions = []
        # Iterate through the routes data dictionary
        for name, route_params in self.routes_data.items():
            time, emission = self._evaluate_route(name, route_params)
            if not pd.isna(time) and not pd.isna(emission): # Only add valid solutions
                 solutions.append({
                    "Lộ trình": name,
                    "Thời gian (phút)": time,
                    "Khí thải (kg)": emission / 1000 # Chuyển đổi sang kg
                })

        # Sort solutions for Pareto front calculation
        solutions.sort(key=lambda x: (x['Thời gian (phút)'], x['Khí thải (kg)']))

        # Find Pareto front
        pareto_front = []
        if solutions:
            pareto_front.append(solutions[0])
            for i in range(1, len(solutions)):
                current_solution = solutions[i]
                is_dominated = False
                for existing_solution in pareto_front:
                    if (existing_solution['Thời gian (phút)'] <= current_solution['Thời gian (phút)'] and
                        existing_solution['Khí thải (kg)'] <= current_solution['Khí thải (kg)']):
                        is_dominated = True
                        break
                if not is_dominated:
                    # Check if the current solution is not equal to the last one in pareto_front
                    # to avoid adding duplicates if objectives are identical
                    if not (pareto_front[-1]['Thời gian (phút)'] == current_solution['Thời gian (phút)'] and
                            pareto_front[-1]['Khí thải (kg)'] == current_solution['Khí thải (kg)']):
                         pareto_front.append(current_solution)


        return pareto_front


    def optimize(self):
        """
        Chạy thuật toán NSGA-II mô phỏng và trả về các giải pháp tối ưu.
        """
        print("\nBắt đầu mô phỏng thuật toán tối ưu hóa NSGA-II...")
        optimal_solutions = self._simulate_nsga2_generations()
        print("Kết thúc mô phỏng.")
        return optimal_solutions

# Define the fixed routes data structure (as in the original NSGAIIOptimizer)
# MODIFIED to include 'model_features' dictionary with placeholder cleaned feature names and values.
# These placeholder values would need to be replaced with actual data mapping route characteristics to model features.
fixed_routes_data_with_features = {
    "Lộ trình 1": {
        "distance": 80,
        "speed": 40,
        "accel": 0.5,
        "model_features": { # Placeholder values - Replace with actual data if available
            'Enginemaxpower': 100,
            'Enginecapacitycm3': 1500,
            'Curb_vehicle_masskg': 1200,
            'VehiclemassWLTPkg': 1300,
            'Vehiclemassrealworldkg': 1350,
            'DeclaredaverageCO2emissionsvalueOEMgkm': 120,
            'DeclaredCO2emissionsvalueSimulatedgkm': 130,
            'Annualaveragedistancekm': 9000
        }
    },
    "Lộ trình 2": {
        "distance": 120,
        "speed": 80,
        "accel": 0.2,
        "model_features": { # Placeholder values
            'Enginemaxpower': 180,
            'Enginecapacitycm3': 2500,
            'Curb_vehicle_masskg': 1800,
            'VehiclemassWLTPkg': 1900,
            'Vehiclemassrealworldkg': 1950,
            'DeclaredaverageCO2emissionsvalueOEMgkm': 150,
            'DeclaredCO2emissionsvalueSimulatedgkm': 160,
            'Annualaveragedistancekm': 10000
        }
    },
    "Lộ trình 3": {
        "distance": 100,
        "speed": 60,
        "accel": 0.8,
        "model_features": { # Placeholder values
            'Enginemaxpower': 140,
            'Enginecapacitycm3': 1800,
            'Curb_vehicle_masskg': 1500,
            'VehiclemassWLTPkg': 1600,
            'Vehiclemassrealworldkg': 1650,
            'DeclaredaverageCO2emissionsvalueOEMgkm': 135,
            'DeclaredCO2emissionsvalueSimulatedgkm': 145,
            'Annualaveragedistancekm': 9500
        }
    },
    "Lộ trình 4": {
        "distance": 90,
        "speed": 50,
        "accel": 0.3,
        "model_features": { # Placeholder values
            'Enginemaxpower': 110,
            'Enginecapacitycm3': 1600,
            'Curb_vehicle_masskg': 1300,
            'VehiclemassWLTPkg': 1400,
            'Vehiclemassrealworldkg': 1450,
            'DeclaredaverageCO2emissionsvalueOEMgkm': 125,
            'DeclaredCO2emissionsvalueSimulatedgkm': 135,
            'Annualaveragedistancekm': 9200
        }
    },
    "Lộ trình 5": {
        "distance": 150,
        "speed": 90,
        "accel": 0.1,
        "model_features": { # Placeholder values
            'Enginemaxpower': 200,
            'Enginecapacitycm3': 3000,
            'Curb_vehicle_masskg': 2000,
            'VehiclemassWLTPkg': 2100,
            'Vehiclemassrealworldkg': 2150,
            'DeclaredaverageCO2emissionsvalueOEMgkm': 160,
            'DeclaredCO2emissionsvalueSimulatedgkm': 170,
            'Annualaveragedistancekm': 11000
        }
    },
}
# --- Tải tệp CSV lên ---
print("Vui lòng tải tệp CSV lên:")
uploaded = files.upload()

if not uploaded:
    print("Không có tệp nào được tải lên. Vui lòng chạy lại ô này và tải tệp CSV lên.")
else:
    # Lấy tên tệp đã tải lên (giả sử chỉ tải lên một tệp)
    file_name = next(iter(uploaded))
    print(f"Đã tải lên tệp: {file_name}")

    # Đọc tệp CSV vào DataFrame
    try:
        # Sử dụng io.StringIO để đọc nội dung nhị phân đã giải mã
        # Thử các mã hóa khác nhau nếu 'utf-8' không hoạt động
        try:
            data_frame = pd.read_csv(io.StringIO(uploaded[file_name].decode('utf-8')))
            print("Đã nhập dữ liệu thành công từ tệp CSV đã tải lên (UTF-8).")
        except UnicodeDecodeError:
            print("Không thể giải mã bằng UTF-8. Thử mã hóa Latin-1...")
            data_frame = pd.read_csv(io.StringIO(uploaded[file_name].decode('latin1')))
            print("Đã nhập dữ liệu thành công từ tệp CSV đã tải lên (Latin-1).")

        print("\n--- Thông tin tổng quan về DataFrame đã tải lên ---")
        data_frame.info()

        print("\n--- 5 dòng đầu tiên của DataFrame ---")
        display(data_frame.head())


    except Exception as e:
        print(f"Đã xảy ra lỗi khi đọc tệp CSV: {e}")
        data_frame = None # Set to None if loading fails


print("\n--- Kết thúc Tải Dữ liệu ---")
# --- Tiền xử lý dữ liệu ---
data_processed_for_model = None # Initialize to None

if 'data_frame' in locals() and data_frame is not None:
    print("\n--- Bắt đầu Tiền xử lý Dữ liệu ---")

    # Xác định các đặc trưng tiềm năng và cột mục tiêu dựa trên tập dữ liệu mới
    # Đảm bảo tên cột khớp chính xác với tệp CSV của bạn
    features_for_model = [
        'Engine max power',
        'Engine capacity [cm3]',
        'Curb_vehicle_mass [kg]',
        'Vehicle mass (WLTP) [kg]',
        'Vehicle mass (real-world) [kg]',
        'Declared average CO2 emissions value (OEM) [g/km]', # Tên cột chính xác
        'Declared CO2 emissions value (Simulated) [g/km]',
        'Annual average distance [km]'
    ]
    target_for_model = 'Real-world CO2 emissions value (Simulated) [g/km]'

    # Kiểm tra sự tồn tại của các cột trong DataFrame
    required_cols_for_model = features_for_model + [target_for_model]
    if not all(col in data_frame.columns for col in required_cols_for_model):
        missing_cols = [col for col in required_cols_for_model if col not in data_frame.columns]
        print(f"Lỗi: Các cột cần thiết cho mô hình sau không được tìm thấy trong DataFrame đã tải lên: {missing_cols}")
        print("Vui lòng kiểm tra lại tên cột trong tệp CSV của bạn và cập nhật danh sách 'features_for_model' và 'target_for_model' cho phù hợp.")
        data_processed_for_model = None # Set to None if data is not valid
    else:
        # Chọn các cột cần thiết
        data_to_process = data_frame[required_cols_for_model].copy()

        # Làm sạch tên cột: loại bỏ các ký tự đặc biệt không được XGBoost chấp nhận
        # Lưu lại ánh xạ tên cột cũ sang tên cột mới nếu cần
        original_columns = data_to_process.columns.tolist()
        data_to_process.columns = data_to_process.columns.str.replace('[^A-Za-z0-9_]+', '', regex=True)
        cleaned_columns = data_to_process.columns.tolist()
        # Note: column_name_map is not used after this cell, but can be kept for reference if needed.
        # column_name_map = dict(zip(original_columns, cleaned_columns))

        # Convert columns to numeric, coercing errors
        for col in data_to_process.columns:
             data_to_process[col] = pd.to_numeric(data_to_process[col], errors='coerce')

        # Handle missing values (drop rows with any NaN in selected columns)
        print(f"\nKích thước DataFrame trước khi xử lý giá trị thiếu: {data_to_process.shape}")
        data_to_process.dropna(inplace=True)
        print(f"Kích thước DataFrame sau khi xử lý giá trị thiếu: {data_to_process.shape}")


        if data_to_process.empty:
            print("Lỗi: DataFrame sau khi xử lý giá trị thiếu bị rỗng. Vui lòng kiểm tra lại dữ liệu hoặc phương pháp xử lý giá trị thiếu.")
            data_processed_for_model = None # Set to None if data is empty

        else:
             # Store the processed data in the designated variable
             data_processed_for_model = data_to_process
             print(f"\nĐã tiền xử lý dữ liệu thành công. Kích thước dữ liệu sẵn sàng cho mô hình: {data_processed_for_model.shape}")


else:
    print("\nKhông tìm thấy DataFrame đã tải lên. Vui lòng chạy ô 'Tải Dữ liệu' trước.")


print("\n--- Kết thúc Tiền xử lý Dữ liệu ---")
# --- Huấn luyện Mô hình Dự đoán Khí thải ---
emission_model = None # Initialize to None

if 'data_processed_for_model' in locals() and data_processed_for_model is not None and not data_processed_for_model.empty:
    print("\n--- Bắt đầu Huấn luyện Mô hình Dự đoán Khí thải ---")
    emission_model = EmissionPredictor()
    # Pass the already processed DataFrame to the train method with the correct keyword argument name
    emission_model.train(data_processed=data_processed_for_model)

    if emission_model.is_fitted:
        print("\nMô hình dự đoán khí thải đã được huấn luyện thành công.")
    else:
        print("\nKhông thể huấn luyện mô hình dự đoán khí thải. Vui lòng kiểm tra các thông báo lỗi trong quá trình huấn luyện.")
else:
    print("\nKhông tìm thấy dữ liệu đã tiền xử lý hợp lệ để huấn luyện mô hình. Vui lòng chạy các bước 'Tải Dữ liệu' và 'Tiền xử lý Dữ liệu' trước.")

print("\n--- Kết thúc Huấn luyện Mô hình ---")
# --- Tối ưu hóa Lộ trình Đa mục tiêu (NSGA-II) ---
# Sử dụng dữ liệu lộ trình mẫu có kèm theo đặc trưng mô hình
# LƯU Ý: Cập nhật 'fixed_routes_data_with_features' với dữ liệu thực tế của bạn nếu có.

# Define the fixed routes data structure with placeholder model features
# These placeholder values need to be replaced with actual data mapping route characteristics to model features.
fixed_routes_data_with_features = {
    "Lộ trình 1": {
        "distance": 80,
        "speed": 40,
        "accel": 0.5,
        "model_features": { # Placeholder values - Replace with actual data if available
            'Enginemaxpower': 100,
            'Enginecapacitycm3': 1500,
            'Curb_vehicle_masskg': 1200,
            'VehiclemassWLTPkg': 1300,
            'Vehiclemassrealworldkg': 1350,
            'DeclaredaverageCO2emissionsvalueOEMgkm': 120,
            'DeclaredCO2emissionsvalueSimulatedgkm': 130,
            'Annualaveragedistancekm': 9000
        }
    },
    "Lộ trình 2": {
        "distance": 120,
        "speed": 80,
        "accel": 0.2,
        "model_features": { # Placeholder values
            'Enginemaxpower': 180,
            'Enginecapacitycm3': 2500,
            'Curb_vehicle_masskg': 1800,
            'VehiclemassWLTPkg': 1900,
            'Vehiclemassrealworldkg': 1950,
            'DeclaredaverageCO2emissionsvalueOEMgkm': 150,
            'DeclaredCO2emissionsvalueSimulatedgkm': 160,
            'Annualaveragedistancekm': 10000
        }
    },
    "Lộ trình 3": {
        "distance": 100,
        "speed": 60,
        "accel": 0.8,
        "model_features": { # Placeholder values
            'Enginemaxpower': 140,
            'Enginecapacitycm3': 1800,
            'Curb_vehicle_masskg': 1500,
            'VehiclemassWLTPkg': 1600,
            'Vehiclemassrealworldkg': 1650,
            'DeclaredaverageCO2emissionsvalueOEMgkm': 135,
            'DeclaredCO2emissionsvalueSimulatedgkm': 145,
            'Annualaveragedistancekm': 9500
        }
    },
    "Lộ trình 4": {
        "distance": 90,
        "speed": 50,
        "accel": 0.3,
        "model_features": { # Placeholder values
            'Enginemaxpower': 110,
            'Enginecapacitycm3': 1600,
            'Curb_vehicle_masskg': 1300,
            'VehiclemassWLTPkg': 1400,
            'Vehiclemassrealworldkg': 1450,
            'DeclaredaverageCO2emissionsvalueOEMgkm': 125,
            'DeclaredCO2emissionsvalueSimulatedgkm': 135,
            'Annualaveragedistancekm': 9200
        }
    },
    "Lộ trình 5": {
        "distance": 150,
        "speed": 90,
        "accel": 0.1,
        "model_features": { # Placeholder values
            'Enginemaxpower': 200,
            'Enginecapacitycm3': 3000,
            'Curb_vehicle_masskg': 2000,
            'VehiclemassWLTPkg': 2100,
            'Vehiclemassrealworldkg': 2150,
            'DeclaredaverageCO2emissionsvalueOEMgkm': 160,
            'DeclaredCO2emissionsvalueSimulatedgkm': 170,
            'Annualaveragedistancekm': 11000
        }
    },
}


if emission_model is not None and emission_model.is_fitted:
    print("\n--- Bắt đầu Tối ưu hóa Lộ trình Đa mục tiêu (NSGA-II) ---")

    # Sử dụng NSGAIIOptimizer với mô hình đã huấn luyện và dữ liệu lộ trình có đặc trưng mô hình
    try:
        route_optimizer = NSGAIIOptimizer(emission_model, fixed_routes_data_with_features)
        optimal_solutions = route_optimizer.optimize()

        print("\n--- Kết quả: Các Lộ trình Tối ưu Pareto ---")
        if optimal_solutions:
            results_df = pd.DataFrame(optimal_solutions)
            display(results_df)

            print("\n--- Phân tích Kết quả ---")
            print("Mỗi hàng trong bảng là một giải pháp tối ưu Pareto.")
            print("Bạn có thể chọn lộ trình phù hợp với ưu tiên của mình (ví dụ: lộ trình có thời gian ngắn nhất với lượng khí thải chấp nhận được, hoặc lộ trình ít khí thải nhất với thời gian chấp nhận được).")
            print("\nLưu ý Quan Trọng về Dữ liệu Lộ trình:")
            print("Các giá trị khí thải trong kết quả này được dự đoán dựa trên mô hình đã huấn luyện và CÁC GIÁ TRỊ ĐẶC TRƯNG MẪU (PLACEHOLDER VALUES) trong 'fixed_routes_data_with_features'.")
            print("Để có kết quả tối ưu hóa chính xác cho các lộ trình THỰC TẾ của bạn, bạn cần cung cấp dữ liệu đặc trưng mô hình (Engine max power, Curb_vehicle_mass, v.v.) tương ứng với từng lộ trình trong cấu trúc dữ liệu lộ trình.")


        else:
            print("Không tìm thấy giải pháp tối ưu. Vui lòng kiểm tra lại dữ liệu lộ trình và mô hình.")

    except ValueError as ve:
        print(f"\nLỗi khi khởi tạo hoặc chạy NSGAIIOptimizer: {ve}")
        print("Vui lòng kiểm tra lại đối tượng EmissionPredictor và cấu trúc dữ liệu lộ trình.")
    except Exception as e:
        print(f"\nĐã xảy ra lỗi không mong muốn trong quá trình tối ưu hóa: {e}")


else:
    print("\nKhông thể tiến hành tối ưu hóa lộ trình do mô hình dự đoán chưa được huấn luyện thành công.")

print("\n--- Kết thúc Tối ưu hóa Lộ trình ---")
